# -*- coding: utf-8 -*-
"""final risk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11CtnuktAZyE-Y7D_lq8U5JaS3PkzPaq1
"""

# -*- coding: utf-8 -*-
"""Enhanced Risk Assessment Module for Falcon 9 Launch AI System"""

import pandas as pd
import joblib
import shap
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, accuracy_score, confusion_matrix,
    f1_score, precision_score, recall_score
)
# from imblearn.over_sampling import SMOTE  # Uncomment if SMOTE is needed

dataset = pd.read_csv('prepared_risk_assessment_dataset.csv')

dataset['Date'] = pd.to_datetime(dataset['Date'], errors='coerce')
dataset['Year'] = dataset['Date'].dt.year
dataset['Month'] = dataset['Date'].dt.month
dataset['Day'] = dataset['Date'].dt.day
dataset = dataset.drop(columns=['Date'])

X = dataset.drop(columns=['RiskLevel'])
y = dataset['RiskLevel']

X = dataset.drop(columns=['RiskLevel']).copy()

X_encoded = pd.get_dummies(X, drop_first=True)

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)

train_test_split(X_encoded, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)
model = grid_search.best_estimator_

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy Score: ", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

predicted_labels = label_encoder.inverse_transform(y_pred)

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)

print("F1 Score: ", f1_score(y_test, y_pred, average='weighted'))
print("Precision Score: ", precision_score(y_test, y_pred, average='weighted'))
print("Recall Score: ", recall_score(y_test, y_pred, average='weighted'))

joblib.dump(model, 'risk_assessment_model.pkl')
joblib.dump(label_encoder, 'label_encoder.pkl')

feature_df = pd.DataFrame({'Feature': X_encoded.columns, 'Importance': model.feature_importances_}).sort_values(by='Importance')
fig = px.bar(feature_df, x='Importance', y='Feature', orientation='h')
fig.show()

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_train)
shap.summary_plot(shap_values, X_train, plot_type="bar")

from sklearn.model_selection import cross_val_score
cv_scores = cross_val_score(model, X_encoded, y_encoded, cv=5)
print("CV Accuracy: ", cv_scores.mean())

import pandas as pd
import joblib
import plotly.graph_objects as go

# Load the saved model and label encoder
model = joblib.load('risk_assessment_model.pkl')
label_encoder = joblib.load('label_encoder.pkl')

# ---- USER INPUT SECTION ----
estimated_cost = float(input("üí∞ Estimated Launch Cost (millions USD): "))

# Construct minimal input based on predefined constants for a new rocket
user_inputs = {
    'Flights': 0,
    'LandingPad': 'N/A',
    'Block': 5,
    'ReusedCount': 0,
    'Serial': 'N/A',
    'Longitude': 0.0,
    'Latitude': 0.0,
    'EstimatedLaunchCost_MillionUSD': estimated_cost
}

user_df = pd.DataFrame([user_inputs])

# Add dummy values for all other required features from the training set
training_features = model.feature_names_in_  # Automatically gets the training feature columns
for col in training_features:
    if col not in user_df.columns:
        user_df[col] = 0

# Reorder to match training input
user_df = user_df[training_features]

# ---- PREDICTION SECTION ----
risk_pred = model.predict(user_df)[0]
risk_label = label_encoder.inverse_transform([risk_pred])[0]
risk_probs = model.predict_proba(user_df)[0]
risk_confidence = risk_probs[risk_pred] * 100  # Convert to percentage

# ---- OUTPUT ----
print(f"\nüõ∞Ô∏è Predicted Risk Level: **{risk_label}**")
print(f"üî¢ Confidence: {risk_confidence:.2f}%")

# Show all class probabilities
print("\nüîç All Risk Class Probabilities:")
for label, prob in zip(label_encoder.classes_, risk_probs):
    print(f"- {label}: {prob*100:.2f}%")

# Optional warning
if risk_confidence < 70:
    print("\n‚ö†Ô∏è Warning: Risk classification has low confidence. Consider reviewing additional mission parameters.")

# ---- GAUGE VISUALIZATION ----
risk_numeric = {'LowRisk': 0, 'MediumRisk': 1, 'HighRisk': 2}
gauge_value = risk_numeric.get(risk_label, 1)

color_map = {'LowRisk': "green", 'MediumRisk': "orange", 'HighRisk': "red"}

fig = go.Figure(go.Indicator(
    mode="gauge+number+delta",
    value=risk_confidence,
    delta={'reference': 100, 'increasing': {'color': "red"}},
    gauge={
        'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
        'bar': {'color': color_map[risk_label]},
        'steps': [
            {'range': [0, 33], 'color': 'lightgreen'},
            {'range': [33, 66], 'color': 'khaki'},
            {'range': [66, 100], 'color': 'salmon'}
        ],
        'threshold': {
            'line': {'color': "black", 'width': 4},
            'thickness': 0.75,
            'value': risk_confidence
        }
    },
    title={'text': f"üöÄ Risk Confidence for {risk_label}", 'font': {'size': 20}}
))

fig.update_layout(height=400)
fig.show()