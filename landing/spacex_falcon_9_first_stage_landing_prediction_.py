# -*- coding: utf-8 -*-
"""spacex-falcon-9-first-stage-landing-prediction (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_YRVIW0ems_FqDslP8Y-xAsUrCh7H-1_

<!--<div style="font-family: Trebuchet MS; font-weight: bold; padding: 12px; font-size: 48px; color: #E7B10A; text-align: center; line-height: 1.25;">
    ðŸš€ Winning Space Race with Data Science:
    <br>
    <span style="color: #000000; font-size: 24px">
        a SpaceX Falcon9 first-stage landing prediction project
    </span>
</div>
<hr><br>

This is my approach for the `Space X Falcon 9 First Stage Landing Prediction` problem, a capstone project for the [IBM Data Science Professional Certificate](https://www.coursera.org/professional-certificates/ibm-data-science). In this project, I explored the fascinating world of space exploration, data science, and machine learning.-->
"""

# Requests allows us to make HTTP requests which we will use to get data from an API
import requests
# Pandas is a software library written for the Python programming language for data manipulation and analysis.
#!pip install -q pandas==1.1.5
import pandas as pd
# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
import numpy as np
# Datetime is a library that allows us to represent dates
import datetime

spacex_url = "https://api.spacexdata.com/v4/launches/past"

response = requests.get(spacex_url)

# We should see that the request was successfull with the 200 status response code
response.status_code

# Use json_normalize meethod to convert the json result into a dataframe
data = pd.json_normalize(response.json())

data.head(2)

"""* The rocket column has no information about the rocket, just an identification number.

* We have to use the API again to get information about the launches using the IDs given for each launch.

* We are specifically interested in using columns <code>rocket</code>, <code>payloads</code>, <code>launchpad</code>, and <code>cores</code>.
"""

# Lets take a subset of our dataframe keeping only the features we want and the flight number, and date_utc.
data = data[['rocket', 'payloads', 'launchpad', 'cores', 'flight_number', 'date_utc']]

# We will remove rows with multiple cores because those are falcon rockets with 2 extra rocket boosters and rows that have multiple payloads in a single rocket.
data = data[data['cores'].map(len)==1]
data = data[data['payloads'].map(len)==1]

# Since payloads and cores are lists of size 1 we will also extract the single value in the list and replace the feature.
data['cores'] = data['cores'].map(lambda x : x[0])
data['payloads'] = data['payloads'].map(lambda x : x[0])

# We also want to convert the date_utc to a datetime datatype and then extracting the date leaving the time
data['date'] = pd.to_datetime(data['date_utc']).dt.date

# Using the date we will restrict the dates of the launches
data = data[data['date'] <= datetime.date(2020, 11, 13)]

data.head(2)

# Global variables
BoosterVersion = []
PayloadMass = []
Orbit = []
LaunchSite = []
Outcome = []
Flights = []
GridFins = []
Reused = []
Legs = []
LandingPad = []
Block = []
ReusedCount = []
Serial = []
Longitude = []
Latitude = []

# Takes the dataset and uses the rocket column to call the API and append the data to the list
def getBoosterVersion(data):
    for x in data['rocket']:
        if x:
            response = requests.get("https://api.spacexdata.com/v4/rockets/"+str(x)).json()
            BoosterVersion.append(response['name'])

# Takes the dataset and uses the launchpad column to call the API and append the data to the list
def getLaunchSite(data):
    for x in data['launchpad']:
        if x:
            response = requests.get("https://api.spacexdata.com/v4/launchpads/"+str(x)).json()
            Longitude.append(response['longitude'])
            Latitude.append(response['latitude'])
            LaunchSite.append(response['name'])

# Takes the dataset and uses the payloads column to call the API and append the data to the lists
def getPayloadData(data):
    for load in data['payloads']:
        if load:
            response = requests.get("https://api.spacexdata.com/v4/payloads/"+load).json()
            PayloadMass.append(response['mass_kg'])
            Orbit.append(response['orbit'])


# Takes the dataset and uses the cores column to call the API and append the data to the lists
def getCoreData(data):
    for core in data['cores']:
        if core['core'] != None:
            response = requests.get("https://api.spacexdata.com/v4/cores/"+core['core']).json()
            Block.append(response['block'])
            ReusedCount.append(response['reuse_count'])
            Serial.append(response['serial'])
        else:
            Block.append(None)
            ReusedCount.append(None)
            Serial.append(None)
        Outcome.append(str(core['landing_success'])+' '+str(core['landing_type']))
        Flights.append(core['flight'])
        GridFins.append(core['gridfins'])
        Reused.append(core['reused'])
        Legs.append(core['legs'])
        LandingPad.append(core['landpad'])

# Calling the functions to get the data from API
getBoosterVersion(data)
getLaunchSite(data)
getPayloadData(data)
getCoreData(data)

# Combine the columns into a dictionary
launch_dict = {'FlightNumber': list(data['flight_number']),
'Date': list(data['date']),
'BoosterVersion':BoosterVersion,
'PayloadMass':PayloadMass,
'Orbit':Orbit,
'LaunchSite':LaunchSite,
'Outcome':Outcome,
'Flights':Flights,
'GridFins':GridFins,
'Reused':Reused,
'Legs':Legs,
'LandingPad':LandingPad,
'Block':Block,
'ReusedCount':ReusedCount,
'Serial':Serial,
'Longitude': Longitude,
'Latitude': Latitude}

# Create a data from launch_dict
data_launch = pd.DataFrame(launch_dict)

data_launch.head(2)

# Filter the data dataframe using the <code>BoosterVersion</code> column to only keep the Falcon 9 launches. Save the filtered data to a new dataframe called <code>data_api</code>.

data_api = data_launch[data_launch['BoosterVersion']=='Falcon 9']

data_api["BoosterVersion"]

# Reset the FlgihtNumber column
data_api.loc[:,'FlightNumber'] = list(range(1, data_api.shape[0]+1))

#!pip3 install beautifulsoup4
#!pip3 install requests

import sys

import requests
from bs4 import BeautifulSoup
import re
import unicodedata
import pandas as pd
import numpy as np

"""<div class="alert alert-block alert-info">ðŸ“Œ For results consistency, this project worked with a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on`9th June 2021`</div>"""

static_url = "https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922"

# Request the HTML page from the above URL and get a `response` object
response = requests.get(static_url)

print(response)

# Create a BeautifulSoup object from a response text content
soup = BeautifulSoup(response.text)

# Find all tables and assign the result to a new list called `html_tables`
html_tables = soup.find_all('table')

# Let's print the target table (third)
first_launch_table = html_tables[2]

# Provided functions for process web scraped HTML table

def extract_column_from_header(row):
    """
    This function returns the column name from the HTML table cell
    Input: the  element of a table data cell extracts extra row
    """
    if (row.br):
        row.br.extract()
    if row.a:
        row.a.extract()
    if row.sup:
        row.sup.extract()

    column_name = ' '.join(row.contents)

    # Filter the digit and empty names
    if not(column_name.strip().isdigit()):
        column_name = column_name.strip()
        return column_name

column_names = []

# Iterate each th element and apply the provided extract_column_from_header() to get a column name
for header in first_launch_table.find_all('th'):
    name = extract_column_from_header(header)
    # Append the Non-empty column name (`if name is not None and len(name) > 0`) into a list called column_names
    if str(name) != 'None' and len(str(name))>0:
        column_names.append(name)

print(column_names)

launch_dict= dict.fromkeys(column_names)

# Remove an irrelvant column
del launch_dict['Date and time ( )']

# Let's initial the launch_dict with each value to be an empty list
launch_dict['Flight No.'] = []
launch_dict['Launch site'] = []
launch_dict['Payload'] = []
launch_dict['Payload mass'] = []
launch_dict['Orbit'] = []
launch_dict['Customer'] = []
launch_dict['Launch outcome'] = []

# Added some new columns
launch_dict['Version Booster'] = []
launch_dict['Booster landing'] = []
launch_dict['Date'] = []
launch_dict['Time'] = []

# Provided functions for process web scraped HTML table


def date_time(table_cells):
    """
    This function returns the data and time from the HTML table cell
    Input: the  element of a table data cell extracts extra row
    """
    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]

def booster_version(table_cells):
    """
    This function returns the booster version from the HTML  table cell
    Input: the  element of a table data cell extracts extra row
    """
    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])
    return out

def landing_status(table_cells):
    """
    This function returns the landing status from the HTML table cell
    Input: the  element of a table data cell extracts extra row
    """
    out=[i for i in table_cells.strings][0]
    return out


def get_mass(table_cells):
    """
    This function returns the pyload mass from the HTML table cell
    Input: the  element of a table data cell extracts extra row
    """
    mass=unicodedata.normalize("NFKD", table_cells.text).strip()
    if mass:
        mass.find("kg")
        new_mass=mass[0:mass.find("kg")+2]
    else:
        new_mass=0
    return new_mass

extracted_row = 0

#Extract each table
for table_number,table in enumerate(soup.find_all('table',"wikitable plainrowheaders collapsible")):
   # get table row
    for rows in table.find_all("tr"):
        #check to see if first table heading is as number corresponding to launch a number
        if rows.th:
            if rows.th.string:
                flight_number=rows.th.string.strip()
                flag=flight_number.isdigit()
        else:
            flag=False
        #get table element
        row=rows.find_all('td')
        #if it is number save cells in a dictonary
        if flag:
            extracted_row += 1
            # Append the flight_number into launch_dict with key `Flight No.`
            launch_dict['Flight No.'].append(flight_number)
            datatimelist=date_time(row[0])

            # Append the date into launch_dict with key `Date`
            date = datatimelist[0].strip(',')
            launch_dict['Date'].append(date)

            # Append the time into launch_dict with key `Time`
            time = datatimelist[1]
            launch_dict['Time'].append(time)

            # Append the bv into launch_dict with key `Version Booster`
            bv=booster_version(row[1])
            if not(bv):
                bv=row[1].a.string
            launch_dict['Version Booster'].append(bv)

            # Append the launch_site into launch_dict with key `Launch Site`
            launch_site = row[2].a.string
            launch_dict['Launch site'].append(launch_site)

            # Append the payload into launch_dict with key `Payload`
            payload = row[3].a.string
            launch_dict['Payload'].append(payload)

            # Append the payload_mass into launch_dict with key `Payload mass`
            payload_mass = get_mass(row[4])
            launch_dict['Payload mass'].append(payload_mass)

            # Append the orbit into launch_dict with key `Orbit`
            orbit = row[5].a.string
            launch_dict['Orbit'].append(orbit)

            # Append the customer into launch_dict with key `Customer`
            if row[6].a:
                customer = row[6].a.string
            else:
                customer = np.nan
            launch_dict['Customer'].append(customer)

            # Append the launch_outcome into launch_dict with key `Launch outcome`
            launch_outcome = list(row[7].strings)[0]
            launch_dict['Launch outcome'].append(launch_outcome)

            # Append the launch_outcome into launch_dict with key `Booster landing`
            booster_landing = landing_status(row[8])
            launch_dict['Booster landing'].append(booster_landing)

# Convert parsed data into a Pandas data frame
data_scrap = pd.DataFrame(launch_dict)

data_scrap.info()

data_api.info()

# Check all null values in data_api
data_api.isnull().sum()

# Replace the payload mass np.nan values with its mean value
mean_payload = data_api['PayloadMass'].mean()
data_api['PayloadMass'].replace(np.nan, mean_payload, inplace=True)

# Check if there is any left null value for payload mass in data_api
data_api['PayloadMass'].isnull().sum()

"""### Determining Training Labels"""

# Print all distinct outcomes
landing_outcomes = data_api['Outcome'].value_counts()

for i,outcome in enumerate(landing_outcomes.keys()):
    print(i,outcome)

# Create a set of outcomes where the second stage did not land successfully
bad_outcomes=set(landing_outcomes.keys()[[1,3,5,6,7]])
bad_outcomes

# Create a landing outcome label from Outcome column
# landing_class = 0 if bad_outcome
# landing_class = 1 otherwise

landing_class = [0 if outcome in bad_outcomes else 1 for outcome in data_api['Outcome']]

data_api['Class']=landing_class

data_api[['Class']].head(8)

"""### Features Engineering"""

# Select the features that will be used in success prediction
features = data_api[['FlightNumber', 'PayloadMass', 'Orbit', 'LaunchSite', 'Flights', 'GridFins', 'Reused', 'Legs', 'LandingPad', 'Block', 'ReusedCount', 'Serial']]
features.head()

# Apply OneHotEncoder categorical columns to create dummy variables

categorical_features = pd.get_dummies(features[['Orbit','LaunchSite','LandingPad','Serial']])
numerical_features = features.drop(['Orbit','LaunchSite','LandingPad','Serial'], axis=1)

features_one_hot = pd.concat([numerical_features, categorical_features], axis=1, join="inner")
features_one_hot.head()

# Cast all numeric columns to `float64`
features_one_hot = features_one_hot.astype('float64')

features_one_hot.info()

"""<a class="anchor"  id="data_visualization"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">4.2. Data Visualization</h2>
"""

# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.
import matplotlib.pyplot as plt
#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics
import seaborn as sns

df=pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv")

sns.catplot(y="PayloadMass", x="FlightNumber", hue="Class", data=df, aspect = 5)
plt.xlabel("Flight Number",fontsize=20)
plt.ylabel("Pay load Mass (kg)",fontsize=20)
plt.show()

"""### ðŸ”Ž Flight Number vs Launch Site"""

# Plot a scatter point chart with x axis to be Flight Number and y axis to be the launch site, and hue to be the class value
sns.catplot(y='LaunchSite', x='FlightNumber', hue='Class', data=df, aspect=5)
plt.xlabel("Flight Number",fontsize=20)
plt.ylabel("Launch Site)",fontsize=20)
plt.show()

"""### ðŸ”Ž Payload vs Launch Site"""

# Plot a scatter point chart with x axis to be Pay Load Mass (kg) and y axis to be the launch site, and hue to be the class value
sns.catplot(y='LaunchSite', x='PayloadMass', hue='Class', data=df, aspect=5)
plt.xlabel("Pay Load Mass (Kg)",fontsize=20)
plt.ylabel("Launch Site)",fontsize=20)
plt.show()

# HINT use groupby method on Orbit column and get the mean of Class column
orbit_success = df.groupby(['Orbit'])['Class'].aggregate(np.average).reset_index().sort_values(['Class','Orbit'], ascending=False)
orbit_success['Class'] = np.round(orbit_success['Class']*100, 2)
sns.barplot(x='Orbit', y='Class', data=orbit_success)
plt.ylabel("Success Rate (%)",fontsize=20)
plt.xlabel("Orbit Type",fontsize=20)
plt.show()

"""### ðŸ”Ž FlightNumber vs Orbit Type"""

# Plot a scatter point chart with x axis to be FlightNumber and y axis to be the Orbit, and hue to be the class value
sns.catplot(x='FlightNumber', y='Orbit', hue='Class', data=df, aspect=5)
plt.xlabel("Flight Number",fontsize=20)
plt.ylabel("Orbit Type",fontsize=20)
plt.show()

"""### ðŸ”Ž Payload vs Orbit Type"""

# Plot a scatter point chart with x axis to be Payload and y axis to be the Orbit, and hue to be the class value
sns.catplot(x='PayloadMass', y='Orbit', hue='Class', data=df, aspect=5)
plt.xlabel("Pay Load Mass (Kg)",fontsize=20)
plt.ylabel("Orbit Type",fontsize=20)
plt.show()

"""### ðŸ”Ž Launch Success Yearly Trend"""

# Plot a line chart with x axis to be the extracted year and y axis to be the success rate

df['Year'] = [i.split("-")[0] for i in df["Date"]]
yearly_success = df.groupby(['Year'])['Class'].aggregate(np.average).reset_index().sort_values('Year')
yearly_success['Class'] = np.round(yearly_success['Class']*100, 2)

sns.lineplot(x='Year',y='Class', data=yearly_success)
plt.xlabel("Year",fontsize=20)
plt.ylabel("Success Rate (%)",fontsize=20)
plt.show()

!pip3 install folium
!pip3 install wget

import folium
import wget
# Import folium MarkerCluster plugin
from folium.plugins import MarkerCluster
# Import folium MousePosition plugin
from folium.plugins import MousePosition
# Import folium DivIcon plugin
from folium.features import DivIcon

"""### Marking all launch sites on a Folium map"""

# Download and read the `spacex_launch_geo.csv`
spacex_csv_file = wget.download('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_geo.csv')
spacex_df=pd.read_csv(spacex_csv_file)

# Select relevant sub-columns: `Launch Site`, `Lat(Latitude)`, `Long(Longitude)`, `class`
spacex_df = spacex_df[['Launch Site', 'Lat', 'Long', 'class']]
launch_sites_df = spacex_df.groupby(['Launch Site'], as_index=False).first()
launch_sites_df = launch_sites_df[['Launch Site', 'Lat', 'Long']]
launch_sites_df

# Create a folium `Map` object, with an initial center location to be NASA Johnson Space Center at Houston, Texas
nasa_coordinate = [29.559684888503615, -95.0830971930759]
site_map = folium.Map(location=nasa_coordinate, zoom_start=10)

# Create a blue circle at NASA Johnson Space Center's coordinate with a popup label showing its name
circle = folium.Circle(nasa_coordinate, radius=1000, color='#d35400', fill=True).add_child(folium.Popup('NASA Johnson Space Center'))

# Create a blue circle at NASA Johnson Space Center's coordinate with a icon showing its name
marker = folium.map.Marker(
    nasa_coordinate,
    # Create an icon as a text label
    icon=DivIcon(
        icon_size=(20,20),
        icon_anchor=(0,0),
        html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % 'NASA JSC',
        )
    )
site_map.add_child(circle)
site_map.add_child(marker)

# For each launch site, add a Circle object based on its coordinate (Lat, Long) values.
for i, row in launch_sites_df.iterrows():
    coordinate = [row['Lat'], row['Long']]
    # In addition, add Launch site name as a popup label
    circle = folium.Circle(coordinate, radius=1000, color='#d35400', fill=True).add_child(folium.Popup(row['Launch Site']))
    marker = folium.map.Marker(coordinate, icon=DivIcon(icon_size=(20,20),icon_anchor=(0,0), html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % row['Launch Site'], ))
    site_map.add_child(circle)
    site_map.add_child(marker)
site_map

# Create a `MarkerCluster` object
marker_cluster = MarkerCluster()

# Assign color to launch outcome
def assign_marker_color(launch_outcome):
    # If class=1, marker_color value will be green
    if launch_outcome == 1:
        return 'green'
    # If class=0, marker_color value will be red
    else:
        return 'red'

spacex_df['marker_color'] = spacex_df['class'].apply(assign_marker_color)
spacex_df.tail(10)

# Add marker_cluster to current site_map
site_map.add_child(marker_cluster)

# Create Marker object with coordinate and customize icon property to indicate if this launch was successed or failed
for i, row in spacex_df.iterrows():
    coordinate = [row['Lat'], row['Long']]
    marker = folium.map.Marker(coordinate, icon=folium.Icon(color='white',icon_color=row['marker_color']))
    marker_cluster.add_child(marker)

site_map

"""### Calculating Distances Between Launch Sites to its Proximities"""

# Add Mouse Position to get the coordinate (Lat, Long) for a mouse over on the map
formatter = "function(num) {return L.Util.formatNum(num, 5);};"
mouse_position = MousePosition(
    position='topright',
    separator=' Long: ',
    empty_string='NaN',
    lng_first=False,
    num_digits=20,
    prefix='Lat:',
    lat_formatter=formatter,
    lng_formatter=formatter,
)

site_map.add_child(mouse_position)
site_map

# Calculate the distance between two points on the map based on their `Lat` and `Long` values

from math import sin, cos, sqrt, atan2, radians

def calculate_distance(lat1, lon1, lat2, lon2):
    # approximate radius of earth in km
    R = 6373.0

    lat1 = radians(lat1)
    lon1 = radians(lon1)
    lat2 = radians(lat2)
    lon2 = radians(lon2)

    dlon = lon2 - lon1
    dlat = lat2 - lat1

    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))

    distance = R * c
    return distance

# Mark down a point on the closest coastline using MousePosition and calculate the distance between the coastline point and the launch site:

launch_site_lat = launch_sites_df['Lat'][1]
launch_site_lon = launch_sites_df['Long'][1]

coastline_lat = 28.56362
coastline_lon = -80.56802

distance_coastline = calculate_distance(launch_site_lat, launch_site_lon, coastline_lat, coastline_lon)

distance_coastline

# Create and add a folium.Marker on the selected closest coastline point on the map
# Display the distance between coastline point and launch site using the icon property

coordinate = [coastline_lat, coastline_lon]

distance_marker = folium.Marker(
   coordinate,
   icon=DivIcon(
       icon_size=(20,20),
       icon_anchor=(0,0),
       html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % "{:10.2f} KM".format(distance_coastline),
    )
)

site_map.add_child(distance_marker)

# Create a `folium.PolyLine` object using the coastline coordinates and launch site coordinate
# lines=folium.PolyLine(locations=coordinates, weight=1)

line=folium.PolyLine(locations=[[launch_site_lat,launch_site_lon],[coastline_lat,coastline_lon]], weight=1)
site_map.add_child(line)

# Create a marker with distance to a closest city, railway, highway, etc.
# Draw a line between the marker to the launch site

closest_city = [28.0948, -80.6369]
closest_railway = [28.57203, -80.58525]
closest_highway = [28.56416, -80.57086]

# Closest City

distance_closest_city = calculate_distance(launch_site_lat, launch_site_lon, closest_city[0], closest_city[1])

city_marker = folium.Marker(
   closest_city,
   icon=DivIcon(
       icon_size=(20,20),
       icon_anchor=(0,0),
       html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % "{:10.2f} KM".format(distance_closest_city),
    )
)

city_line = folium.PolyLine(locations=[[launch_site_lat,launch_site_lon],closest_city], weight=1)

site_map.add_child(city_marker)
site_map.add_child(city_line)

# Closest Railway
distance_closest_railway = calculate_distance(launch_site_lat, launch_site_lon, closest_railway[0], closest_railway[1])

railway_marker = folium.Marker(
   closest_railway,
   icon=DivIcon(
       icon_size=(20,20),
       icon_anchor=(0,0),
       html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % "{:10.2f} KM".format(distance_closest_railway),
    )
)

railway_line = folium.PolyLine(locations=[[launch_site_lat,launch_site_lon],closest_railway], weight=1)

site_map.add_child(railway_marker)
site_map.add_child(railway_line)

# Closest Highway
distance_closest_highway = calculate_distance(launch_site_lat, launch_site_lon, closest_highway[0], closest_highway[1])

highway_marker = folium.Marker(
   closest_highway,
   icon=DivIcon(
       icon_size=(20,20),
       icon_anchor=(0,0),
       html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % "{:10.2f} KM".format(distance_closest_highway),
    )
)

highway_line = folium.PolyLine(locations=[[launch_site_lat,launch_site_lon],closest_highway], weight=1)

site_map.add_child(highway_marker)
site_map.add_child(highway_line)

"""<a class="anchor"  id="interactive_dashboard"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">4.4. Interactive Dashboard</h2>
"""

!wget "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_dash.csv"

"""### Python Code"""

!pip install dash

# Import required libraries
import pandas as pd
import dash
from dash import html
from dash import dcc
from dash.dependencies import Input, Output
import plotly.express as px

# Read the airline data into pandas dataframe
spacex_df = pd.read_csv("spacex_launch_dash.csv")
spacex_df['Launch Outcome'] = ['Success' if c == 1 else 'Failure' for c in spacex_df['class']]
max_payload = spacex_df['Payload Mass (kg)'].max()
min_payload = spacex_df['Payload Mass (kg)'].min()

# Create a dash application
app = dash.Dash(__name__)

# Create an app layout and CSS style
app.layout = html.Div(children = [
    html.H1('SpaceX Launch Records Dashboard',
            style = {'textAlign': 'center', 'color': '#503D36', 'font-size': 40}),

    # TASK 1: Add a dropdown list to enable Launch Site selection
    # The default select value is for ALL sites
    dcc.Dropdown(id = 'site-dropdown',
                options = [
                            {'label': 'All Sites',
                                'value': 'ALL'},
                            {'label': 'CCAFS LC-40',
                                'value': 'CCAFS LC-40'},
                            {'label': 'CCAFS SLC-40',
                                'value': 'CCAFS SLC-40'},
                            {'label': 'KSC LC-39A',
                                'value': 'KSC LC-39A'},
                            {'label': 'VAFB SLC-4E',
                                'value': 'VAFB SLC-4E'}],
                value = 'ALL',
                placeholder = 'Launch Site:',
                searchable = True ),

    # TASK 2: Add a pie chart to show the total successful launches count for all sites
    # If a specific launch site was selected, show the Success vs. Failed counts for the site
    html.Div(dcc.Graph(id = 'success-pie-chart')),
    html.Br(),
    html.P("Payload range (Kg):"),

    # TASK 3: Add a slider to select payload range
    # dcc.RangeSlider(id='payload-slider',...)
    dcc.RangeSlider(id = 'payload-slider',
                    min = 0, max = 10000, step = 1000,
                    marks = {0: '0',
                            1000: '1000',
                            2000: '2000',
                            3000: '3000',
                            4000: '4000',
                            5000: '5000',
                            6000: '6000',
                            7000: '7000',
                            8000: '8000',
                            9000: '9000',
                            10000: '10000'},
                    value = [min_payload, max_payload]),

    # TASK 4: Add a scatter chart to show the correlation between payload and launch success
    html.Div(
        dcc.Graph(id = 'success-payload-scatter-chart')),
    ], style = {'height': '100vh'}
)

# TASK 2:
# Add a callback function for `site-dropdown` as input, `success-pie-chart` as output
@app.callback(Output(component_id = 'success-pie-chart', component_property = 'figure'),
              Input(component_id = 'site-dropdown', component_property = 'value'))
def get_pie_chart(entered_site):
    filtered_df = spacex_df
    if entered_site == 'ALL':
        fig = px.pie(filtered_df, values = 'class',
                     names = 'Launch Site',
                     title = 'SpaceX Launch Site Success Distribution (All Sites)')
        return fig
    else:
        # return the outcomes piechart for a selected site
        filtered_df = spacex_df[spacex_df['Launch Site'] == entered_site]
        filtered_df = filtered_df.groupby(['Launch Site', 'class']).size().reset_index(name = 'class_count')
        fig = px.pie(filtered_df, values = 'class_count', names = filtered_df['class'].map({1: "Success", 0: "Failure"}),
                     title = f"SpaceX Success Rate of {entered_site} Launch Site")
        fig.update_traces(marker = dict(colors=['red', 'green']))
        return fig

# TASK 4:
# Add a callback function for `site-dropdown` and `payload-slider` as inputs, `success-payload-scatter-chart` as output
@app.callback(Output(component_id = 'success-payload-scatter-chart', component_property = 'figure'),
              [Input(component_id = 'site-dropdown', component_property = 'value'),
               Input(component_id = 'payload-slider', component_property = 'value')])
def get_scatter_chart(entered_site, payload):
    filtered_df = spacex_df[spacex_df['Payload Mass (kg)'].between(
        payload[0], payload[1])]
    if entered_site == 'ALL':
        fig = px.scatter(filtered_df, x = 'Payload Mass (kg)', y = 'Launch Outcome',
                         color = 'Booster Version Category', title = 'Success vs. Failure for Payload Mass and Launch Sites (All Sites)')
        return fig
    else:
        fig = px.scatter(filtered_df[filtered_df['Launch Site'] == entered_site], x = 'Payload Mass (kg)', y = 'Launch Outcome',
                         color = 'Booster Version Category', title = f"Success vs. Failure for Payload Mass and Launch Site {entered_site}")
        return fig


# Run the app
if __name__ == '__main__':
    app.run()

"""<h1 id="predective_analysis" style="font-family: Trebuchet MS; font-weight: bold; background-color: #E7B10A; color: #FFFFFF; padding: 15px; line-height: 1.5; border-radius:10px">
5| Predictive Analysis
<a class="anchor-link" href="#predective_analysis"></a></h1>

### Import Libraries and Define Auxiliary Functions
"""

# Preprocessing allows us to standarsize our data
from sklearn import preprocessing
# Allows us to split our data into training and testing data
from sklearn.model_selection import train_test_split
# Allows us to test parameters of classification algorithms and find the best one
from sklearn.model_selection import GridSearchCV
# Logistic Regression classification algorithm
from sklearn.linear_model import LogisticRegression
# Support Vector Machine classification algorithm
from sklearn.svm import SVC
# Decision Tree classification algorithm
from sklearn.tree import DecisionTreeClassifier
# K Nearest Neighbors classification algorithm
from sklearn.neighbors import KNeighborsClassifier

# This provided function is to plot the confusion matrix.
def plot_confusion_matrix(y,y_predict):
    "this function plots the confusion matrix"
    from sklearn.metrics import confusion_matrix

    cm = confusion_matrix(y, y_predict)
    ax= plt.subplot()
    sns.heatmap(cm, annot=True, ax = ax); # annot=True to annotate cells
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title('Confusion Matrix');
    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])

"""### Load the dataframe"""

data = pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv")

data.head()

X = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv')

X.head()

"""### Preparing the Data"""

# Create a NumPy array from the column Class
y = data['Class'].to_numpy()
y

# Standardize the data in X
transform = preprocessing.StandardScaler()
X = transform.fit_transform(X)
X

# Split the data X and Y into training and test data
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=2)
y_test.shape

"""<a class="anchor"  id="lr"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">5.1. Logistic Regression Model (LR)</h2>
"""

parameters ={'C':[0.01,0.1,1],
             'penalty':['l2'],
             'solver':['lbfgs']}


lr=LogisticRegression()
logreg_cv = GridSearchCV(lr, parameters, cv=10).fit(X_train, y_train)

print("LR Tuned Hyperparameters (best parameters):",logreg_cv.best_params_)
print("LR Train Accuracy:",logreg_cv.best_score_)

"""### Calculate the Accuracy on the Test Data"""

logreg_accuracy = logreg_cv.score(X_test, y_test)
print("LR Test Accuracy:",logreg_accuracy)

"""### Plot LR Confusion Matrix"""

yhat = logreg_cv.predict(X_test)
plot_confusion_matrix(y_test,yhat)

"""<a class="anchor"  id="svm"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">5.2. Support Vector Machine Model (SVM)</h2>
"""

parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),
              'C': np.logspace(-3, 3, 5),
              'gamma':np.logspace(-3, 3, 5)}
svm = SVC()

grid_search = GridSearchCV(svm, parameters, cv=10)
svm_cv = grid_search.fit(X_train, y_train)

print("SVM Tuned Hyperparameters (best parameters):",svm_cv.best_params_)
print("SVM Train Accuracy:",svm_cv.best_score_)

"""### Calculate the Accuracy on the Test Data"""

svm_accuracy = svm_cv.score(X_test, y_test)
print("SVM Test Accuracy:",svm_accuracy)

"""### Plot SVM Confusion Matrix"""

yhat=svm_cv.predict(X_test)
plot_confusion_matrix(y_test,yhat)

"""<a class="anchor" id="dt"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">5.3. Decision Tree Model (DT)</h2>
"""

#----------Filter out the UserWarning related to 'max_features'='auto'----------
import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn.tree")
#---------------------------------------------------------------------------------


parameters = {'criterion': ['gini', 'entropy'],
     'splitter': ['best', 'random'],
     'max_depth': [2*n for n in range(1,10)],
     'max_features': ['auto','sqrt'],
     'min_samples_leaf': [1, 2, 4],
     'min_samples_split': [2, 5, 10]}

tree = DecisionTreeClassifier()

grid_search = GridSearchCV(tree, parameters, cv=10)
tree_cv = grid_search.fit(X_train, y_train)

print("DT Tuned Hyperparameters (best parameters):",tree_cv.best_params_)
print("DT Train Accuracy:",tree_cv.best_score_)

"""### Calculate the Accuracy on the Test Data"""

tree_accuracy = tree_cv.score(X_test, y_test)
print("DT Test Accuracy:",tree_accuracy)

"""### Plot DT Confusion Matrix"""

yhat = tree_cv.predict(X_test)
plot_confusion_matrix(y_test,yhat)

"""<a class="anchor" id="knn"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">5.4. K-Nearest Neighbors Model (KNN)</h2>
"""

parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
              'p': [1,2]}

KNN = KNeighborsClassifier()

grid_search = GridSearchCV(KNN, parameters, cv=10)
knn_cv = grid_search.fit(X_train, y_train)

print("KNN Tuned Hyperparameters (best parameters):",knn_cv.best_params_)
print("KNN Train Accuracy:",knn_cv.best_score_)

"""### Calculate the Accuracy on the Test Data"""

knn_accuracy = knn_cv.score(X_test, y_test)
print("KNN Test Accuracy:",knn_accuracy)

"""### Plot KNN Confusion Matrix"""

yhat = knn_cv.predict(X_test)
plot_confusion_matrix(y_test,yhat)

"""<h1 id="conclusion" style="font-family: Trebuchet MS; font-weight: bold; background-color: #E7B10A; color: #FFFFFF; padding: 15px; line-height: 1.5; border-radius:10px">
6| Conclusion
<a class="anchor-link" href="#conclusion"></a></h1>

<a class="anchor" id="comparing_models_performance"></a>
## <h2 style="font-family: Trebuchet MS; font-size: 20px; font-weight: bold; color: #E7B10A; line-height: 1; margin: 0px">6.1. Comparing Models Performance</h2>
"""

print('LR Accuracy:', '{:.2%}'.format(logreg_accuracy))
print( 'SVM Accuracy:', '{:.2%}'.format(svm_accuracy))
print('Decision Tree Accuracy:', '{:.2%}'.format(tree_accuracy))
print('KNN Accuracy:', '{:.2%}'.format(knn_accuracy))

model_accuracies = {
    'LR': logreg_accuracy,
    'SVM': svm_accuracy,
    'Tree': tree_accuracy,
    'KNN': knn_accuracy
}


# Extract model names and accuracies
model_names = list(model_accuracies.keys())
accuracies = list(model_accuracies.values())

# Create a bar chart
plt.figure(figsize=(10, 6))
plt.bar(model_names, accuracies, color='skyblue')
plt.xlabel('Classification Models')
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')
plt.ylim(0, 1)  # Set the y-axis limit between 0 and 1

# Display the accuracy values on top of the bars
for i, accuracy in enumerate(accuracies):
    plt.text(i, accuracy, f'{accuracy:.2f}', ha='center', va='bottom')

plt.xticks(rotation=45)
plt.tight_layout()

# Show the bar chart
plt.show()